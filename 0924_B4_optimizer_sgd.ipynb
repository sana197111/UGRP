{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd15f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS']='0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bddad8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/media/windows/'\n",
    "training = ALL_DATA_DIR + 'training/'\n",
    "validation = ALL_DATA_DIR + 'validation/'\n",
    "scaled = ALL_DATA_DIR + 'scaled/'\n",
    "scaled_wo_rotate = ALL_DATA_DIR + \"scaled_wo_rotate/\"\n",
    "\n",
    "scaled_wo_rotate_training = scaled_wo_rotate + \"training/\"\n",
    "scaled_wo_rotate_validation = scaled_wo_rotate + \"validation/\"\n",
    "\n",
    "datFile = training + \"shape_predictor_68_face_landmarks.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c83fcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "img_height = 224\n",
    "img_width = 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a89e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399839 files belonging to 7 classes.\n",
      "Found 50947 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "training_s = tf.keras.utils.image_dataset_from_directory(scaled_wo_rotate_training, labels = 'inferred',\n",
    "            image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)\n",
    "validation_s = tf.keras.utils.image_dataset_from_directory(scaled_wo_rotate_validation, labels = 'inferred', \n",
    "            image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1bd9cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.EfficientNetB4(input_shape=(224,224,3), include_top = False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12aec1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(7, activation='softmax')(avg)\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cde5774",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b90e5b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "op = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=op,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55fb4ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12495/12495 [==============================] - 2018s 161ms/step - loss: 1.4169 - accuracy: 0.4557 - val_loss: 1.3359 - val_accuracy: 0.4991\n",
      "Epoch 2/5\n",
      "12495/12495 [==============================] - 1985s 159ms/step - loss: 1.3436 - accuracy: 0.4875 - val_loss: 1.2881 - val_accuracy: 0.5154\n",
      "Epoch 3/5\n",
      "12495/12495 [==============================] - 1997s 160ms/step - loss: 1.3237 - accuracy: 0.4962 - val_loss: 1.2657 - val_accuracy: 0.5193\n",
      "Epoch 4/5\n",
      "12495/12495 [==============================] - 1985s 159ms/step - loss: 1.3137 - accuracy: 0.5008 - val_loss: 1.2591 - val_accuracy: 0.5262\n",
      "Epoch 5/5\n",
      "12495/12495 [==============================] - 2000s 160ms/step - loss: 1.3069 - accuracy: 0.5039 - val_loss: 1.2639 - val_accuracy: 0.5318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4c137d9190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_s, validation_data=validation_s, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b257c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a191e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095d2ecf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fef656",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12495/12495 [==============================] - 8978s 717ms/step - loss: 1.2696 - accuracy: 0.5332 - val_loss: 0.9659 - val_accuracy: 0.6408\n",
      "Epoch 2/10\n",
      "12495/12495 [==============================] - 8945s 716ms/step - loss: 0.9557 - accuracy: 0.6409 - val_loss: 0.8689 - val_accuracy: 0.6757\n",
      "Epoch 3/10\n",
      "12495/12495 [==============================] - 8909s 713ms/step - loss: 0.8810 - accuracy: 0.6696 - val_loss: 0.8178 - val_accuracy: 0.6934\n",
      "Epoch 4/10\n",
      "12495/12495 [==============================] - 8974s 718ms/step - loss: 0.8334 - accuracy: 0.6881 - val_loss: 0.7836 - val_accuracy: 0.7071\n",
      "Epoch 5/10\n",
      "12495/12495 [==============================] - 8922s 714ms/step - loss: 0.7969 - accuracy: 0.7019 - val_loss: 0.7558 - val_accuracy: 0.7185\n",
      "Epoch 6/10\n",
      "12495/12495 [==============================] - 9002s 720ms/step - loss: 0.7674 - accuracy: 0.7130 - val_loss: 0.7334 - val_accuracy: 0.7287\n",
      "Epoch 7/10\n",
      "12495/12495 [==============================] - 8943s 716ms/step - loss: 0.7407 - accuracy: 0.7236 - val_loss: 0.7129 - val_accuracy: 0.7376\n",
      "Epoch 8/10\n",
      "12495/12495 [==============================] - 8969s 718ms/step - loss: 0.7177 - accuracy: 0.7326 - val_loss: 0.6956 - val_accuracy: 0.7456\n",
      "Epoch 9/10\n",
      "12495/12495 [==============================] - 8994s 720ms/step - loss: 0.6958 - accuracy: 0.7409 - val_loss: 0.6798 - val_accuracy: 0.7531\n",
      "Epoch 10/10\n",
      "12495/12495 [==============================] - 8898s 712ms/step - loss: 0.6750 - accuracy: 0.7490 - val_loss: 0.6643 - val_accuracy: 0.7599\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(training_s, validation_data=validation_s, epochs=10, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a99d8b14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495/12495 [==============================] - 1750s 140ms/step - loss: 0.5897 - accuracy: 0.7830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5896645784378052, 0.783017635345459]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab616d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593/1593 [==============================] - 226s 142ms/step - loss: 0.6643 - accuracy: 0.7599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6642904281616211, 0.7599465847015381]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc52154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"0924_B4_nesterov.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
