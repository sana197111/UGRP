{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd15f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bddad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/media/windows/'\n",
    "training = ALL_DATA_DIR + 'training/'\n",
    "validation = ALL_DATA_DIR + 'validation/'\n",
    "scaled = ALL_DATA_DIR + 'scaled/'\n",
    "scaled_wo_rotate = ALL_DATA_DIR + \"scaled_wo_rotate/\"\n",
    "\n",
    "scaled_wo_rotate_training = scaled_wo_rotate + \"training/\"\n",
    "scaled_wo_rotate_validation = scaled_wo_rotate + \"validation/\"\n",
    "\n",
    "datFile = training + \"shape_predictor_68_face_landmarks.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c83fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "img_height = 224\n",
    "img_width = 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74be57c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43733 files belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 12:17:57.272955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:57.281499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:57.284216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:57.287696: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-01 12:17:57.288076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:57.290668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:57.293227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:58.031574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:58.033341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:58.034879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-01 12:17:58.036378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13596 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    scaled_wo_rotate_validation, \n",
    "    labels = 'inferred', \n",
    "    image_size=(img_height,img_width)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf486cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 349639 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "training_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    scaled_wo_rotate_training, \n",
    "    labels = 'inferred', \n",
    "    image_size=(img_height,img_width)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1bd9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 6\n",
    "base_model = tf.keras.applications.MobileNetV3Small(input_shape = (224,224,3), include_top = False, weights='imagenet')\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_class, activation=\"softmax\")(avg)\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e9b6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a191e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c414cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 224, 224, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Conv (Conv2D)                  (None, 112, 112, 16  432         ['rescaling[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv/BatchNorm (BatchNormaliza  (None, 112, 112, 16  64         ['Conv[0][0]']                   \n",
      " tion)                          )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 112, 112, 16  0          ['Conv/BatchNorm[0][0]']         \n",
      " da)                            )                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 112, 112, 16  0           ['tf.__operators__.add[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 112, 112, 16  0           ['re_lu[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 112, 112, 16  0           ['Conv/BatchNorm[0][0]',         \n",
      "                                )                                 'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/pad (Z  (None, 113, 113, 16  0          ['multiply[0][0]']               \n",
      " eroPadding2D)                  )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise (Depth  (None, 56, 56, 16)  144         ['expanded_conv/depthwise/pad[0][\n",
      " wiseConv2D)                                                     0]']                             \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/BatchN  (None, 56, 56, 16)  64          ['expanded_conv/depthwise[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 56, 56, 16)   0           ['expanded_conv/depthwise/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/A  (None, 1, 1, 16)    0           ['re_lu_1[0][0]']                \n",
      " vgPool (GlobalAveragePooling2D                                                                   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/C  (None, 1, 1, 8)     136         ['expanded_conv/squeeze_excite/Av\n",
      " onv (Conv2D)                                                    gPool[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/R  (None, 1, 1, 8)     0           ['expanded_conv/squeeze_excite/Co\n",
      " elu (ReLU)                                                      nv[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/C  (None, 1, 1, 16)    144         ['expanded_conv/squeeze_excite/Re\n",
      " onv_1 (Conv2D)                                                  lu[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 1, 1, 16)    0           ['expanded_conv/squeeze_excite/Co\n",
      " mbda)                                                           nv_1[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 1, 1, 16)     0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 1, 1, 16)    0           ['re_lu_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv/squeeze_excite/M  (None, 56, 56, 16)  0           ['re_lu_1[0][0]',                \n",
      " ul (Multiply)                                                    'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv/project (Conv2D)  (None, 56, 56, 16)  256         ['expanded_conv/squeeze_excite/Mu\n",
      "                                                                 l[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv/project/BatchNor  (None, 56, 56, 16)  64          ['expanded_conv/project[0][0]']  \n",
      " m (BatchNormalization)                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand (Conv2D  (None, 56, 56, 72)  1152        ['expanded_conv/project/BatchNorm\n",
      " )                                                               [0][0]']                         \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand/BatchNo  (None, 56, 56, 72)  288         ['expanded_conv_1/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 56, 56, 72)   0           ['expanded_conv_1/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/pad   (None, 57, 57, 72)  0           ['re_lu_3[0][0]']                \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise (Dep  (None, 28, 28, 72)  648         ['expanded_conv_1/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " expanded_conv_1/depthwise/Batc  (None, 28, 28, 72)  288         ['expanded_conv_1/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 28, 28, 72)   0           ['expanded_conv_1/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_1/project (Conv2  (None, 28, 28, 24)  1728        ['re_lu_4[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_1/project/BatchN  (None, 28, 28, 24)  96          ['expanded_conv_1/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand (Conv2D  (None, 28, 28, 88)  2112        ['expanded_conv_1/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand/BatchNo  (None, 28, 28, 88)  352         ['expanded_conv_2/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 28, 28, 88)   0           ['expanded_conv_2/expand/BatchNor\n",
      "                                                                 m[0][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise (Dep  (None, 28, 28, 88)  792         ['re_lu_5[0][0]']                \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise/Batc  (None, 28, 28, 88)  352         ['expanded_conv_2/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 28, 28, 88)   0           ['expanded_conv_2/depthwise/Batch\n",
      "                                                                 Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_2/project (Conv2  (None, 28, 28, 24)  2112        ['re_lu_6[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/project/BatchN  (None, 28, 28, 24)  96          ['expanded_conv_2/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_2/Add (Add)      (None, 28, 28, 24)   0           ['expanded_conv_1/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_2/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand (Conv2D  (None, 28, 28, 96)  2304        ['expanded_conv_2/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand/BatchNo  (None, 28, 28, 96)  384         ['expanded_conv_3/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 28, 28, 96)  0           ['expanded_conv_3/expand/BatchNor\n",
      " mbda)                                                           m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 28, 28, 96)   0           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 28, 28, 96)  0           ['re_lu_7[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 28, 28, 96)   0           ['expanded_conv_3/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_2[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/pad   (None, 31, 31, 96)  0           ['multiply_1[0][0]']             \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise (Dep  (None, 14, 14, 96)  2400        ['expanded_conv_3/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/Batc  (None, 14, 14, 96)  384         ['expanded_conv_3/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 14, 14, 96)  0           ['expanded_conv_3/depthwise/Batch\n",
      " mbda)                                                           Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 14, 14, 96)   0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 14, 14, 96)  0           ['re_lu_8[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 14, 14, 96)   0           ['expanded_conv_3/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_3[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    0           ['multiply_2[0][0]']             \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    2328        ['expanded_conv_3/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    0           ['expanded_conv_3/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    2400        ['expanded_conv_3/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 1, 1, 96)    0           ['expanded_conv_3/squeeze_excite/\n",
      " mbda)                                                           Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 1, 1, 96)     0           ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 1, 1, 96)    0           ['re_lu_9[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_excite  (None, 14, 14, 96)  0           ['multiply_2[0][0]',             \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_4[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv_3/project (Conv2  (None, 14, 14, 40)  3840        ['expanded_conv_3/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_3/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_3/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand (Conv2D  (None, 14, 14, 240)  9600       ['expanded_conv_3/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand/BatchNo  (None, 14, 14, 240)  960        ['expanded_conv_4/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 14, 14, 240)  0          ['expanded_conv_4/expand/BatchNor\n",
      " mbda)                                                           m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 14, 14, 240)  0          ['re_lu_10[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 14, 14, 240)  0           ['expanded_conv_4/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise (Dep  (None, 14, 14, 240)  6000       ['multiply_3[0][0]']             \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise/Batc  (None, 14, 14, 240)  960        ['expanded_conv_4/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 14, 14, 240)  0          ['expanded_conv_4/depthwise/Batch\n",
      " mbda)                                                           Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 14, 14, 240)  0          ['re_lu_11[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 14, 14, 240)  0           ['expanded_conv_4/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_6[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_4[0][0]']             \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_4/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_4/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_4/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 1, 1, 240)   0           ['expanded_conv_4/squeeze_excite/\n",
      " mbda)                                                           Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 1, 1, 240)    0           ['tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 1, 1, 240)   0           ['re_lu_12[0][0]']               \n",
      " )                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_excite  (None, 14, 14, 240)  0          ['multiply_4[0][0]',             \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_7[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv_4/project (Conv2  (None, 14, 14, 40)  9600        ['expanded_conv_4/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_4/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_4/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_4/Add (Add)      (None, 14, 14, 40)   0           ['expanded_conv_3/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_4/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand (Conv2D  (None, 14, 14, 240)  9600       ['expanded_conv_4/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand/BatchNo  (None, 14, 14, 240)  960        ['expanded_conv_5/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 14, 14, 240)  0          ['expanded_conv_5/expand/BatchNor\n",
      " mbda)                                                           m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 14, 14, 240)  0          ['re_lu_13[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 14, 14, 240)  0           ['expanded_conv_5/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_8[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise (Dep  (None, 14, 14, 240)  6000       ['multiply_5[0][0]']             \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise/Batc  (None, 14, 14, 240)  960        ['expanded_conv_5/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 14, 14, 240)  0          ['expanded_conv_5/depthwise/Batch\n",
      " mbda)                                                           Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 14, 14, 240)  0           ['tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None, 14, 14, 240)  0          ['re_lu_14[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 14, 14, 240)  0           ['expanded_conv_5/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_9[0][0]']     \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_6[0][0]']             \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_5/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_5/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_5/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 1, 1, 240)   0           ['expanded_conv_5/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 1, 1, 240)    0           ['tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpLambd  (None, 1, 1, 240)   0           ['re_lu_15[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_excite  (None, 14, 14, 240)  0          ['multiply_6[0][0]',             \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_10[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_5/project (Conv2  (None, 14, 14, 40)  9600        ['expanded_conv_5/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_5/project/BatchN  (None, 14, 14, 40)  160         ['expanded_conv_5/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_5/Add (Add)      (None, 14, 14, 40)   0           ['expanded_conv_4/Add[0][0]',    \n",
      "                                                                  'expanded_conv_5/project/BatchNo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand (Conv2D  (None, 14, 14, 120)  4800       ['expanded_conv_5/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand/BatchNo  (None, 14, 14, 120)  480        ['expanded_conv_6/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 14, 14, 120)  0          ['expanded_conv_6/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 14, 14, 120)  0           ['tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpLambd  (None, 14, 14, 120)  0          ['re_lu_16[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 14, 14, 120)  0           ['expanded_conv_6/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_11[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise (Dep  (None, 14, 14, 120)  3000       ['multiply_7[0][0]']             \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise/Batc  (None, 14, 14, 120)  480        ['expanded_conv_6/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 14, 14, 120)  0          ['expanded_conv_6/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 14, 14, 120)  0           ['tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpLambd  (None, 14, 14, 120)  0          ['re_lu_17[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 14, 14, 120)  0           ['expanded_conv_6/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_12[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   0           ['multiply_8[0][0]']             \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    3872        ['expanded_conv_6/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    0           ['expanded_conv_6/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   3960        ['expanded_conv_6/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 1, 1, 120)   0           ['expanded_conv_6/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 1, 1, 120)    0           ['tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpLambd  (None, 1, 1, 120)   0           ['re_lu_18[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_6/squeeze_excite  (None, 14, 14, 120)  0          ['multiply_8[0][0]',             \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_13[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_6/project (Conv2  (None, 14, 14, 48)  5760        ['expanded_conv_6/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_6/project/BatchN  (None, 14, 14, 48)  192         ['expanded_conv_6/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand (Conv2D  (None, 14, 14, 144)  6912       ['expanded_conv_6/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand/BatchNo  (None, 14, 14, 144)  576        ['expanded_conv_7/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 14, 14, 144)  0          ['expanded_conv_7/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 14, 14, 144)  0           ['tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpLambd  (None, 14, 14, 144)  0          ['re_lu_19[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 14, 14, 144)  0           ['expanded_conv_7/expand/BatchNor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_14[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise (Dep  (None, 14, 14, 144)  3600       ['multiply_9[0][0]']             \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise/Batc  (None, 14, 14, 144)  576        ['expanded_conv_7/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 14, 14, 144)  0          ['expanded_conv_7/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 14, 14, 144)  0           ['tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpLambd  (None, 14, 14, 144)  0          ['re_lu_20[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)         (None, 14, 14, 144)  0           ['expanded_conv_7/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_15[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   0           ['multiply_10[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    5800        ['expanded_conv_7/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    0           ['expanded_conv_7/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   5904        ['expanded_conv_7/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 1, 1, 144)   0           ['expanded_conv_7/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 1, 1, 144)    0           ['tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpLambd  (None, 1, 1, 144)   0           ['re_lu_21[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_7/squeeze_excite  (None, 14, 14, 144)  0          ['multiply_10[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_16[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_7/project (Conv2  (None, 14, 14, 48)  6912        ['expanded_conv_7/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_7/project/BatchN  (None, 14, 14, 48)  192         ['expanded_conv_7/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_7/Add (Add)      (None, 14, 14, 48)   0           ['expanded_conv_6/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_7/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand (Conv2D  (None, 14, 14, 288)  13824      ['expanded_conv_7/Add[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand/BatchNo  (None, 14, 14, 288)  1152       ['expanded_conv_8/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 14, 14, 288)  0          ['expanded_conv_8/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 14, 14, 288)  0           ['tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpLambd  (None, 14, 14, 288)  0          ['re_lu_22[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)         (None, 14, 14, 288)  0           ['expanded_conv_8/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_17[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/pad   (None, 17, 17, 288)  0          ['multiply_11[0][0]']            \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise (Dep  (None, 7, 7, 288)   7200        ['expanded_conv_8/depthwise/pad[0\n",
      " thwiseConv2D)                                                   ][0]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/Batc  (None, 7, 7, 288)   1152        ['expanded_conv_8/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_18 (TFOpL  (None, 7, 7, 288)   0           ['expanded_conv_8/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 7, 7, 288)    0           ['tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpLambd  (None, 7, 7, 288)   0           ['re_lu_23[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_12 (Multiply)         (None, 7, 7, 288)    0           ['expanded_conv_8/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_18[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   0           ['multiply_12[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    20808       ['expanded_conv_8/squeeze_excite/\n",
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    0           ['expanded_conv_8/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   21024       ['expanded_conv_8/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 1, 1, 288)   0           ['expanded_conv_8/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 1, 1, 288)    0           ['tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpLambd  (None, 1, 1, 288)   0           ['re_lu_24[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_8/squeeze_excite  (None, 7, 7, 288)   0           ['multiply_12[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_19[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_8/project (Conv2  (None, 7, 7, 96)    27648       ['expanded_conv_8/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_8/project/BatchN  (None, 7, 7, 96)    384         ['expanded_conv_8/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand (Conv2D  (None, 7, 7, 576)   55296       ['expanded_conv_8/project/BatchNo\n",
      " )                                                               rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand/BatchNo  (None, 7, 7, 576)   2304        ['expanded_conv_9/expand[0][0]'] \n",
      " rm (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_9/expand/BatchNor\n",
      " ambda)                                                          m[0][0]']                        \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_25[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_13 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_9/expand/BatchNor\n",
      "                                                                 m[0][0]',                        \n",
      "                                                                  'tf.math.multiply_20[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise (Dep  (None, 7, 7, 576)   14400       ['multiply_13[0][0]']            \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise/Batc  (None, 7, 7, 576)   2304        ['expanded_conv_9/depthwise[0][0]\n",
      " hNorm (BatchNormalization)                                      ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_9/depthwise/Batch\n",
      " ambda)                                                          Norm[0][0]']                     \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_26[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_14 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_9/depthwise/Batch\n",
      "                                                                 Norm[0][0]',                     \n",
      "                                                                  'tf.math.multiply_21[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   0           ['multiply_14[0][0]']            \n",
      " /AvgPool (GlobalAveragePooling                                                                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   83088       ['expanded_conv_9/squeeze_excite/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   0           ['expanded_conv_9/squeeze_excite/\n",
      " /Relu (ReLU)                                                    Conv[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   83520       ['expanded_conv_9/squeeze_excite/\n",
      " /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 1, 1, 576)   0           ['expanded_conv_9/squeeze_excite/\n",
      " ambda)                                                          Conv_1[0][0]']                   \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 1, 1, 576)    0           ['tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpLambd  (None, 1, 1, 576)   0           ['re_lu_27[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_9/squeeze_excite  (None, 7, 7, 576)   0           ['multiply_14[0][0]',            \n",
      " /Mul (Multiply)                                                  'tf.math.multiply_22[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_9/project (Conv2  (None, 7, 7, 96)    55296       ['expanded_conv_9/squeeze_excite/\n",
      " D)                                                              Mul[0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_9/project/BatchN  (None, 7, 7, 96)    384         ['expanded_conv_9/project[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " expanded_conv_9/Add (Add)      (None, 7, 7, 96)     0           ['expanded_conv_8/project/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'expanded_conv_9/project/BatchNo\n",
      "                                                                 rm[0][0]']                       \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand (Conv2  (None, 7, 7, 576)   55296       ['expanded_conv_9/Add[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand/BatchN  (None, 7, 7, 576)   2304        ['expanded_conv_10/expand[0][0]']\n",
      " orm (BatchNormalization)                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_10/expand/BatchNo\n",
      " ambda)                                                          rm[0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_23[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_28[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_15 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_10/expand/BatchNo\n",
      "                                                                 rm[0][0]',                       \n",
      "                                                                  'tf.math.multiply_23[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise (De  (None, 7, 7, 576)   14400       ['multiply_15[0][0]']            \n",
      " pthwiseConv2D)                                                                                   \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise/Bat  (None, 7, 7, 576)   2304        ['expanded_conv_10/depthwise[0][0\n",
      " chNorm (BatchNormalization)                                     ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 7, 7, 576)   0           ['expanded_conv_10/depthwise/Batc\n",
      " ambda)                                                          hNorm[0][0]']                    \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_29[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_16 (Multiply)         (None, 7, 7, 576)    0           ['expanded_conv_10/depthwise/Batc\n",
      "                                                                 hNorm[0][0]',                    \n",
      "                                                                  'tf.math.multiply_24[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   0           ['multiply_16[0][0]']            \n",
      " e/AvgPool (GlobalAveragePoolin                                                                   \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   83088       ['expanded_conv_10/squeeze_excite\n",
      " e/Conv (Conv2D)                                                 /AvgPool[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   0           ['expanded_conv_10/squeeze_excite\n",
      " e/Relu (ReLU)                                                   /Conv[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   83520       ['expanded_conv_10/squeeze_excite\n",
      " e/Conv_1 (Conv2D)                                               /Relu[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 1, 1, 576)   0           ['expanded_conv_10/squeeze_excite\n",
      " ambda)                                                          /Conv_1[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 1, 1, 576)    0           ['tf.__operators__.add_25[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpLambd  (None, 1, 1, 576)   0           ['re_lu_30[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_excit  (None, 7, 7, 576)   0           ['multiply_16[0][0]',            \n",
      " e/Mul (Multiply)                                                 'tf.math.multiply_25[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv_10/project (Conv  (None, 7, 7, 96)    55296       ['expanded_conv_10/squeeze_excite\n",
      " 2D)                                                             /Mul[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_10/project/Batch  (None, 7, 7, 96)    384         ['expanded_conv_10/project[0][0]'\n",
      " Norm (BatchNormalization)                                       ]                                \n",
      "                                                                                                  \n",
      " expanded_conv_10/Add (Add)     (None, 7, 7, 96)     0           ['expanded_conv_9/Add[0][0]',    \n",
      "                                                                  'expanded_conv_10/project/BatchN\n",
      "                                                                 orm[0][0]']                      \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 576)    55296       ['expanded_conv_10/Add[0][0]']   \n",
      "                                                                                                  \n",
      " Conv_1/BatchNorm (BatchNormali  (None, 7, 7, 576)   2304        ['Conv_1[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 7, 7, 576)   0           ['Conv_1/BatchNorm[0][0]']       \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 7, 7, 576)    0           ['tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpLambd  (None, 7, 7, 576)   0           ['re_lu_31[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " multiply_17 (Multiply)         (None, 7, 7, 576)    0           ['Conv_1/BatchNorm[0][0]',       \n",
      "                                                                  'tf.math.multiply_26[0][0]']    \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 576)         0           ['multiply_17[0][0]']            \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            3462        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 942,582\n",
      "Trainable params: 3,462\n",
      "Non-trainable params: 939,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2568bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b94f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_raw, valid_set_raw, train_set_raw = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "891e67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
    "\n",
    "def random_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
    "    return tf.image.random_crop(image, [min_dim, min_dim, 3])\n",
    "\n",
    "def resized(image, label, randomize=False):\n",
    "    if randomize:\n",
    "        cropped_image = random_crop(image)\n",
    "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "    else:\n",
    "        cropped_image = central_crop(image)\n",
    "    resized_image = tf.image.resize(cropped_image, [224, 224])\n",
    "    return resized_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6153803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5bc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set_raw.shuffle(1000).repeat()\n",
    "train_set = train_set.map(partial(resized, randomize=True)).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(resized).batch(batch_size).prefetch(1)\n",
    "test_set = test_set_raw.map(resized).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a11ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = info.splits[\"train\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a202ca1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 12:19:07.308375: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 9s 44ms/step - loss: 0.9632 - accuracy: 0.6562 - val_loss: 0.6248 - val_accuracy: 0.7923\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.5031 - accuracy: 0.8463 - val_loss: 0.4961 - val_accuracy: 0.8474\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.3977 - accuracy: 0.8775 - val_loss: 0.4565 - val_accuracy: 0.8585\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.3457 - accuracy: 0.8961 - val_loss: 0.4134 - val_accuracy: 0.8768\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.3147 - accuracy: 0.8935 - val_loss: 0.4000 - val_accuracy: 0.8695\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.2876 - accuracy: 0.9062 - val_loss: 0.3865 - val_accuracy: 0.8805\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.2749 - accuracy: 0.9081 - val_loss: 0.3781 - val_accuracy: 0.8768\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.2520 - accuracy: 0.9161 - val_loss: 0.3636 - val_accuracy: 0.8915\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 2s 28ms/step - loss: 0.2464 - accuracy: 0.9142 - val_loss: 0.3562 - val_accuracy: 0.8915\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.2307 - accuracy: 0.9248 - val_loss: 0.3530 - val_accuracy: 0.8897\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "454154cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bea36eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7547b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c0fb3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "86/86 [==============================] - 11s 68ms/step - loss: 0.4363 - accuracy: 0.8477 - val_loss: 0.3467 - val_accuracy: 0.8915\n",
      "Epoch 2/200\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.3610 - accuracy: 0.8739 - val_loss: 0.3432 - val_accuracy: 0.8952\n",
      "Epoch 3/200\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.3458 - accuracy: 0.8826 - val_loss: 0.3392 - val_accuracy: 0.8897\n",
      "Epoch 4/200\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.3193 - accuracy: 0.8943 - val_loss: 0.3353 - val_accuracy: 0.8897\n",
      "Epoch 5/200\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.3042 - accuracy: 0.8986 - val_loss: 0.3298 - val_accuracy: 0.8934\n",
      "Epoch 6/200\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.2885 - accuracy: 0.9033 - val_loss: 0.3261 - val_accuracy: 0.8897\n",
      "Epoch 7/200\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.2708 - accuracy: 0.9073 - val_loss: 0.3220 - val_accuracy: 0.8934\n",
      "Epoch 8/200\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.2492 - accuracy: 0.9182 - val_loss: 0.3180 - val_accuracy: 0.8934\n",
      "Epoch 9/200\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.2325 - accuracy: 0.9277 - val_loss: 0.3138 - val_accuracy: 0.8952\n",
      "Epoch 10/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.2282 - accuracy: 0.9251 - val_loss: 0.3099 - val_accuracy: 0.8934\n",
      "Epoch 11/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.2247 - accuracy: 0.9310 - val_loss: 0.3047 - val_accuracy: 0.8934\n",
      "Epoch 12/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.2082 - accuracy: 0.9346 - val_loss: 0.3009 - val_accuracy: 0.8989\n",
      "Epoch 13/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.2106 - accuracy: 0.9328 - val_loss: 0.2984 - val_accuracy: 0.8989\n",
      "Epoch 14/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1968 - accuracy: 0.9382 - val_loss: 0.2952 - val_accuracy: 0.9007\n",
      "Epoch 15/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.2031 - accuracy: 0.9331 - val_loss: 0.2917 - val_accuracy: 0.9026\n",
      "Epoch 16/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1861 - accuracy: 0.9408 - val_loss: 0.2905 - val_accuracy: 0.9044\n",
      "Epoch 17/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1814 - accuracy: 0.9422 - val_loss: 0.2867 - val_accuracy: 0.9062\n",
      "Epoch 18/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1713 - accuracy: 0.9448 - val_loss: 0.2850 - val_accuracy: 0.9044\n",
      "Epoch 19/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1623 - accuracy: 0.9509 - val_loss: 0.2823 - val_accuracy: 0.9081\n",
      "Epoch 20/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1636 - accuracy: 0.9509 - val_loss: 0.2804 - val_accuracy: 0.9099\n",
      "Epoch 21/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1611 - accuracy: 0.9491 - val_loss: 0.2788 - val_accuracy: 0.9099\n",
      "Epoch 22/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1492 - accuracy: 0.9531 - val_loss: 0.2772 - val_accuracy: 0.9081\n",
      "Epoch 23/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1620 - accuracy: 0.9473 - val_loss: 0.2756 - val_accuracy: 0.9118\n",
      "Epoch 24/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1374 - accuracy: 0.9575 - val_loss: 0.2722 - val_accuracy: 0.9173\n",
      "Epoch 25/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1402 - accuracy: 0.9593 - val_loss: 0.2706 - val_accuracy: 0.9173\n",
      "Epoch 26/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1371 - accuracy: 0.9589 - val_loss: 0.2689 - val_accuracy: 0.9191\n",
      "Epoch 27/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1378 - accuracy: 0.9542 - val_loss: 0.2675 - val_accuracy: 0.9191\n",
      "Epoch 28/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1230 - accuracy: 0.9655 - val_loss: 0.2659 - val_accuracy: 0.9191\n",
      "Epoch 29/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.1180 - accuracy: 0.9691 - val_loss: 0.2656 - val_accuracy: 0.9191\n",
      "Epoch 30/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1120 - accuracy: 0.9677 - val_loss: 0.2646 - val_accuracy: 0.9210\n",
      "Epoch 31/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.1142 - accuracy: 0.9673 - val_loss: 0.2642 - val_accuracy: 0.9210\n",
      "Epoch 32/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.1243 - accuracy: 0.9575 - val_loss: 0.2627 - val_accuracy: 0.9191\n",
      "Epoch 33/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.1116 - accuracy: 0.9684 - val_loss: 0.2618 - val_accuracy: 0.9210\n",
      "Epoch 34/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.1076 - accuracy: 0.9702 - val_loss: 0.2612 - val_accuracy: 0.9191\n",
      "Epoch 35/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0996 - accuracy: 0.9698 - val_loss: 0.2608 - val_accuracy: 0.9191\n",
      "Epoch 36/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.1083 - accuracy: 0.9677 - val_loss: 0.2602 - val_accuracy: 0.9210\n",
      "Epoch 37/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.0961 - accuracy: 0.9724 - val_loss: 0.2582 - val_accuracy: 0.9228\n",
      "Epoch 38/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0956 - accuracy: 0.9717 - val_loss: 0.2571 - val_accuracy: 0.9210\n",
      "Epoch 39/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.1043 - accuracy: 0.9662 - val_loss: 0.2566 - val_accuracy: 0.9228\n",
      "Epoch 40/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0946 - accuracy: 0.9709 - val_loss: 0.2571 - val_accuracy: 0.9228\n",
      "Epoch 41/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0931 - accuracy: 0.9702 - val_loss: 0.2564 - val_accuracy: 0.9246\n",
      "Epoch 42/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0829 - accuracy: 0.9793 - val_loss: 0.2555 - val_accuracy: 0.9265\n",
      "Epoch 43/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0743 - accuracy: 0.9793 - val_loss: 0.2556 - val_accuracy: 0.9228\n",
      "Epoch 44/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0749 - accuracy: 0.9804 - val_loss: 0.2551 - val_accuracy: 0.9228\n",
      "Epoch 45/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0803 - accuracy: 0.9793 - val_loss: 0.2558 - val_accuracy: 0.9210\n",
      "Epoch 46/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0796 - accuracy: 0.9789 - val_loss: 0.2560 - val_accuracy: 0.9228\n",
      "Epoch 47/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0853 - accuracy: 0.9764 - val_loss: 0.2565 - val_accuracy: 0.9228\n",
      "Epoch 48/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0855 - accuracy: 0.9749 - val_loss: 0.2555 - val_accuracy: 0.9228\n",
      "Epoch 49/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0671 - accuracy: 0.9836 - val_loss: 0.2560 - val_accuracy: 0.9246\n",
      "Epoch 50/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.0626 - accuracy: 0.9829 - val_loss: 0.2556 - val_accuracy: 0.9228\n",
      "Epoch 51/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0700 - accuracy: 0.9815 - val_loss: 0.2564 - val_accuracy: 0.9210\n",
      "Epoch 52/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0752 - accuracy: 0.9771 - val_loss: 0.2572 - val_accuracy: 0.9246\n",
      "Epoch 53/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0586 - accuracy: 0.9855 - val_loss: 0.2573 - val_accuracy: 0.9228\n",
      "Epoch 54/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0683 - accuracy: 0.9811 - val_loss: 0.2582 - val_accuracy: 0.9228\n",
      "Epoch 55/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0651 - accuracy: 0.9844 - val_loss: 0.2586 - val_accuracy: 0.9246\n",
      "Epoch 56/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0576 - accuracy: 0.9851 - val_loss: 0.2588 - val_accuracy: 0.9246\n",
      "Epoch 57/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0627 - accuracy: 0.9826 - val_loss: 0.2583 - val_accuracy: 0.9246\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 0.2578 - val_accuracy: 0.9246\n",
      "Epoch 59/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0519 - accuracy: 0.9862 - val_loss: 0.2586 - val_accuracy: 0.9246\n",
      "Epoch 60/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0550 - accuracy: 0.9869 - val_loss: 0.2591 - val_accuracy: 0.9210\n",
      "Epoch 61/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0530 - accuracy: 0.9851 - val_loss: 0.2590 - val_accuracy: 0.9210\n",
      "Epoch 62/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0512 - accuracy: 0.9858 - val_loss: 0.2594 - val_accuracy: 0.9228\n",
      "Epoch 63/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0547 - accuracy: 0.9862 - val_loss: 0.2595 - val_accuracy: 0.9228\n",
      "Epoch 64/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0528 - accuracy: 0.9873 - val_loss: 0.2599 - val_accuracy: 0.9228\n",
      "Epoch 65/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0462 - accuracy: 0.9895 - val_loss: 0.2617 - val_accuracy: 0.9210\n",
      "Epoch 66/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0431 - accuracy: 0.9898 - val_loss: 0.2618 - val_accuracy: 0.9228\n",
      "Epoch 67/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0476 - accuracy: 0.9898 - val_loss: 0.2635 - val_accuracy: 0.9228\n",
      "Epoch 68/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0436 - accuracy: 0.9906 - val_loss: 0.2640 - val_accuracy: 0.9210\n",
      "Epoch 69/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0462 - accuracy: 0.9873 - val_loss: 0.2630 - val_accuracy: 0.9210\n",
      "Epoch 70/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0413 - accuracy: 0.9869 - val_loss: 0.2643 - val_accuracy: 0.9228\n",
      "Epoch 71/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0324 - accuracy: 0.9953 - val_loss: 0.2647 - val_accuracy: 0.9210\n",
      "Epoch 72/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0431 - accuracy: 0.9895 - val_loss: 0.2645 - val_accuracy: 0.9246\n",
      "Epoch 73/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0427 - accuracy: 0.9909 - val_loss: 0.2662 - val_accuracy: 0.9210\n",
      "Epoch 74/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0411 - accuracy: 0.9902 - val_loss: 0.2685 - val_accuracy: 0.9228\n",
      "Epoch 75/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0361 - accuracy: 0.9927 - val_loss: 0.2670 - val_accuracy: 0.9228\n",
      "Epoch 76/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0374 - accuracy: 0.9920 - val_loss: 0.2679 - val_accuracy: 0.9210\n",
      "Epoch 77/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0465 - accuracy: 0.9869 - val_loss: 0.2681 - val_accuracy: 0.9210\n",
      "Epoch 78/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0389 - accuracy: 0.9920 - val_loss: 0.2672 - val_accuracy: 0.9191\n",
      "Epoch 79/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0370 - accuracy: 0.9913 - val_loss: 0.2674 - val_accuracy: 0.9210\n",
      "Epoch 80/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 0.2665 - val_accuracy: 0.9228\n",
      "Epoch 81/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0321 - accuracy: 0.9935 - val_loss: 0.2685 - val_accuracy: 0.9228\n",
      "Epoch 82/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0380 - accuracy: 0.9891 - val_loss: 0.2701 - val_accuracy: 0.9191\n",
      "Epoch 83/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0363 - accuracy: 0.9913 - val_loss: 0.2683 - val_accuracy: 0.9191\n",
      "Epoch 84/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0361 - accuracy: 0.9920 - val_loss: 0.2687 - val_accuracy: 0.9228\n",
      "Epoch 85/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0286 - accuracy: 0.9942 - val_loss: 0.2705 - val_accuracy: 0.9191\n",
      "Epoch 86/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0344 - accuracy: 0.9913 - val_loss: 0.2699 - val_accuracy: 0.9228\n",
      "Epoch 87/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0287 - accuracy: 0.9945 - val_loss: 0.2703 - val_accuracy: 0.9191\n",
      "Epoch 88/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0291 - accuracy: 0.9935 - val_loss: 0.2708 - val_accuracy: 0.9210\n",
      "Epoch 89/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0302 - accuracy: 0.9924 - val_loss: 0.2689 - val_accuracy: 0.9246\n",
      "Epoch 90/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0262 - accuracy: 0.9938 - val_loss: 0.2727 - val_accuracy: 0.9210\n",
      "Epoch 91/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0272 - accuracy: 0.9942 - val_loss: 0.2746 - val_accuracy: 0.9191\n",
      "Epoch 92/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0296 - accuracy: 0.9935 - val_loss: 0.2730 - val_accuracy: 0.9173\n",
      "Epoch 93/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0303 - accuracy: 0.9931 - val_loss: 0.2750 - val_accuracy: 0.9191\n",
      "Epoch 94/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0258 - accuracy: 0.9949 - val_loss: 0.2777 - val_accuracy: 0.9191\n",
      "Epoch 95/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0250 - accuracy: 0.9945 - val_loss: 0.2781 - val_accuracy: 0.9154\n",
      "Epoch 96/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.2749 - val_accuracy: 0.9210\n",
      "Epoch 97/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0276 - accuracy: 0.9942 - val_loss: 0.2759 - val_accuracy: 0.9210\n",
      "Epoch 98/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.2751 - val_accuracy: 0.9210\n",
      "Epoch 99/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.2788 - val_accuracy: 0.9228\n",
      "Epoch 100/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0250 - accuracy: 0.9945 - val_loss: 0.2780 - val_accuracy: 0.9210\n",
      "Epoch 101/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.2782 - val_accuracy: 0.9210\n",
      "Epoch 102/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.2790 - val_accuracy: 0.9210\n",
      "Epoch 103/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0233 - accuracy: 0.9945 - val_loss: 0.2809 - val_accuracy: 0.9191\n",
      "Epoch 104/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.2831 - val_accuracy: 0.9191\n",
      "Epoch 105/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.2835 - val_accuracy: 0.9191\n",
      "Epoch 106/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 0.2807 - val_accuracy: 0.9191\n",
      "Epoch 107/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 0.2811 - val_accuracy: 0.9191\n",
      "Epoch 108/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0218 - accuracy: 0.9967 - val_loss: 0.2818 - val_accuracy: 0.9210\n",
      "Epoch 109/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0180 - accuracy: 0.9964 - val_loss: 0.2812 - val_accuracy: 0.9210\n",
      "Epoch 110/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0174 - accuracy: 0.9967 - val_loss: 0.2834 - val_accuracy: 0.9210\n",
      "Epoch 111/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0237 - accuracy: 0.9956 - val_loss: 0.2847 - val_accuracy: 0.9210\n",
      "Epoch 112/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.2837 - val_accuracy: 0.9210\n",
      "Epoch 113/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.2825 - val_accuracy: 0.9228\n",
      "Epoch 114/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0199 - accuracy: 0.9964 - val_loss: 0.2812 - val_accuracy: 0.9265\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 0.2811 - val_accuracy: 0.9210\n",
      "Epoch 116/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 0.2808 - val_accuracy: 0.9228\n",
      "Epoch 117/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0211 - accuracy: 0.9953 - val_loss: 0.2831 - val_accuracy: 0.9191\n",
      "Epoch 118/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0147 - accuracy: 0.9982 - val_loss: 0.2857 - val_accuracy: 0.9191\n",
      "Epoch 119/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0180 - accuracy: 0.9956 - val_loss: 0.2896 - val_accuracy: 0.9210\n",
      "Epoch 120/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.2886 - val_accuracy: 0.9228\n",
      "Epoch 121/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.2891 - val_accuracy: 0.9228\n",
      "Epoch 122/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.2909 - val_accuracy: 0.9228\n",
      "Epoch 123/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.2928 - val_accuracy: 0.9246\n",
      "Epoch 124/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0179 - accuracy: 0.9975 - val_loss: 0.2944 - val_accuracy: 0.9228\n",
      "Epoch 125/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.2920 - val_accuracy: 0.9228\n",
      "Epoch 126/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0193 - accuracy: 0.9964 - val_loss: 0.2907 - val_accuracy: 0.9228\n",
      "Epoch 127/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.2878 - val_accuracy: 0.9228\n",
      "Epoch 128/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.2869 - val_accuracy: 0.9246\n",
      "Epoch 129/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2889 - val_accuracy: 0.9246\n",
      "Epoch 130/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 0.2892 - val_accuracy: 0.9265\n",
      "Epoch 131/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.2895 - val_accuracy: 0.9265\n",
      "Epoch 132/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.2918 - val_accuracy: 0.9228\n",
      "Epoch 133/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.2920 - val_accuracy: 0.9210\n",
      "Epoch 134/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.2914 - val_accuracy: 0.9228\n",
      "Epoch 135/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.2915 - val_accuracy: 0.9210\n",
      "Epoch 136/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 0.2897 - val_accuracy: 0.9246\n",
      "Epoch 137/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.2887 - val_accuracy: 0.9246\n",
      "Epoch 138/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0123 - accuracy: 0.9982 - val_loss: 0.2910 - val_accuracy: 0.9265\n",
      "Epoch 139/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.2923 - val_accuracy: 0.9301\n",
      "Epoch 140/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0125 - accuracy: 0.9978 - val_loss: 0.2879 - val_accuracy: 0.9320\n",
      "Epoch 141/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.2901 - val_accuracy: 0.9301\n",
      "Epoch 142/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.2923 - val_accuracy: 0.9265\n",
      "Epoch 143/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.0108 - accuracy: 0.9985 - val_loss: 0.2935 - val_accuracy: 0.9265\n",
      "Epoch 144/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.2945 - val_accuracy: 0.9283\n",
      "Epoch 145/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.2971 - val_accuracy: 0.9301\n",
      "Epoch 146/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.2997 - val_accuracy: 0.9283\n",
      "Epoch 147/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.3017 - val_accuracy: 0.9246\n",
      "Epoch 148/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.3003 - val_accuracy: 0.9246\n",
      "Epoch 149/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.3018 - val_accuracy: 0.9246\n",
      "Epoch 150/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.3064 - val_accuracy: 0.9228\n",
      "Epoch 151/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.3048 - val_accuracy: 0.9210\n",
      "Epoch 152/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.3050 - val_accuracy: 0.9246\n",
      "Epoch 153/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.3065 - val_accuracy: 0.9246\n",
      "Epoch 154/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.3033 - val_accuracy: 0.9265\n",
      "Epoch 155/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.3053 - val_accuracy: 0.9228\n",
      "Epoch 156/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.3028 - val_accuracy: 0.9246\n",
      "Epoch 157/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.3016 - val_accuracy: 0.9246\n",
      "Epoch 158/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.3029 - val_accuracy: 0.9246\n",
      "Epoch 159/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.3037 - val_accuracy: 0.9283\n",
      "Epoch 160/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.3041 - val_accuracy: 0.9265\n",
      "Epoch 161/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 0.3046 - val_accuracy: 0.9265\n",
      "Epoch 162/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.3006 - val_accuracy: 0.9265\n",
      "Epoch 163/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.3007 - val_accuracy: 0.9265\n",
      "Epoch 164/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.2987 - val_accuracy: 0.9265\n",
      "Epoch 165/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.3020 - val_accuracy: 0.9265\n",
      "Epoch 166/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.3014 - val_accuracy: 0.9246\n",
      "Epoch 167/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.3002 - val_accuracy: 0.9283\n",
      "Epoch 168/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.3003 - val_accuracy: 0.9283\n",
      "Epoch 169/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.3015 - val_accuracy: 0.9301\n",
      "Epoch 170/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.3014 - val_accuracy: 0.9301\n",
      "Epoch 171/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.3070 - val_accuracy: 0.9283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.3089 - val_accuracy: 0.9283\n",
      "Epoch 173/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.3106 - val_accuracy: 0.9301\n",
      "Epoch 174/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.3056 - val_accuracy: 0.9283\n",
      "Epoch 175/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.3040 - val_accuracy: 0.9301\n",
      "Epoch 176/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.3080 - val_accuracy: 0.9283\n",
      "Epoch 177/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.3083 - val_accuracy: 0.9301\n",
      "Epoch 178/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.3087 - val_accuracy: 0.9283\n",
      "Epoch 179/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.3063 - val_accuracy: 0.9283\n",
      "Epoch 180/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.3069 - val_accuracy: 0.9301\n",
      "Epoch 181/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.3108 - val_accuracy: 0.9301\n",
      "Epoch 182/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.3125 - val_accuracy: 0.9265\n",
      "Epoch 183/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.3140 - val_accuracy: 0.9283\n",
      "Epoch 184/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.3181 - val_accuracy: 0.9265\n",
      "Epoch 185/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.3124 - val_accuracy: 0.9265\n",
      "Epoch 186/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.3117 - val_accuracy: 0.9265\n",
      "Epoch 187/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.3115 - val_accuracy: 0.9283\n",
      "Epoch 188/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.3077 - val_accuracy: 0.9265\n",
      "Epoch 189/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.3057 - val_accuracy: 0.9301\n",
      "Epoch 190/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.3039 - val_accuracy: 0.9283\n",
      "Epoch 191/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.3072 - val_accuracy: 0.9283\n",
      "Epoch 192/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.3093 - val_accuracy: 0.9283\n",
      "Epoch 193/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.3114 - val_accuracy: 0.9283\n",
      "Epoch 194/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.3124 - val_accuracy: 0.9283\n",
      "Epoch 195/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.3136 - val_accuracy: 0.9265\n",
      "Epoch 196/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.3113 - val_accuracy: 0.9265\n",
      "Epoch 197/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.3131 - val_accuracy: 0.9246\n",
      "Epoch 198/200\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.3100 - val_accuracy: 0.9246\n",
      "Epoch 199/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.3119 - val_accuracy: 0.9246\n",
      "Epoch 200/200\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.3117 - val_accuracy: 0.9246\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a22e98a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 41ms/step - loss: 0.2125 - accuracy: 0.9373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21250896155834198, 0.9373297095298767]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff56a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist = 'history.csv' \n",
    "with open(hist, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
