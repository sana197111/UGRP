{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd15f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS']='0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bddad8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/media/windows/'\n",
    "training = ALL_DATA_DIR + 'training/'\n",
    "validation = ALL_DATA_DIR + 'validation/'\n",
    "scaled = ALL_DATA_DIR + 'scaled/'\n",
    "scaled_wo_rotate = ALL_DATA_DIR + \"scaled_wo_rotate/\"\n",
    "\n",
    "scaled_wo_rotate_training = scaled_wo_rotate + \"training/\"\n",
    "scaled_wo_rotate_validation = scaled_wo_rotate + \"validation/\"\n",
    "\n",
    "datFile = training + \"shape_predictor_68_face_landmarks.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c83fcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "img_height = 224\n",
    "img_width = 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a89e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399839 files belonging to 7 classes.\n",
      "Found 50947 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "training_s = tf.keras.utils.image_dataset_from_directory(scaled_wo_rotate_training, labels = 'inferred',\n",
    "            image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)\n",
    "validation_s = tf.keras.utils.image_dataset_from_directory(scaled_wo_rotate_validation, labels = 'inferred', \n",
    "            image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1bd9cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.EfficientNetB4(input_shape=(224,224,3), include_top = False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd386762",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21fbc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(224,224,3))\n",
    "x = base_model(inputs, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12aec1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(7, activation='softmax')(avg)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b90e5b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55fb4ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "12495/12495 [==============================] - 1981s 157ms/step - loss: 1.3707 - accuracy: 0.4747 - val_loss: 1.3041 - val_accuracy: 0.5082\n",
      "Epoch 2/25\n",
      "12495/12495 [==============================] - 1949s 156ms/step - loss: 1.2814 - accuracy: 0.5137 - val_loss: 1.2604 - val_accuracy: 0.5226\n",
      "Epoch 3/25\n",
      "12495/12495 [==============================] - 1972s 158ms/step - loss: 1.2562 - accuracy: 0.5240 - val_loss: 1.2492 - val_accuracy: 0.5302\n",
      "Epoch 4/25\n",
      "12495/12495 [==============================] - 1978s 158ms/step - loss: 1.2431 - accuracy: 0.5296 - val_loss: 1.2404 - val_accuracy: 0.5347\n",
      "Epoch 5/25\n",
      "12495/12495 [==============================] - 1972s 158ms/step - loss: 1.2341 - accuracy: 0.5336 - val_loss: 1.2341 - val_accuracy: 0.5368\n",
      "Epoch 6/25\n",
      "12495/12495 [==============================] - 1962s 157ms/step - loss: 1.2285 - accuracy: 0.5361 - val_loss: 1.2372 - val_accuracy: 0.5335\n",
      "Epoch 7/25\n",
      "12495/12495 [==============================] - 1964s 157ms/step - loss: 1.2240 - accuracy: 0.5379 - val_loss: 1.2331 - val_accuracy: 0.5317\n",
      "Epoch 8/25\n",
      "12495/12495 [==============================] - 1977s 158ms/step - loss: 1.2207 - accuracy: 0.5394 - val_loss: 1.2405 - val_accuracy: 0.5244\n",
      "Epoch 9/25\n",
      "12495/12495 [==============================] - 1972s 158ms/step - loss: 1.2182 - accuracy: 0.5398 - val_loss: 1.2258 - val_accuracy: 0.5377\n",
      "Epoch 10/25\n",
      "12495/12495 [==============================] - 1976s 158ms/step - loss: 1.2165 - accuracy: 0.5410 - val_loss: 1.2195 - val_accuracy: 0.5389\n",
      "Epoch 11/25\n",
      "12495/12495 [==============================] - 1965s 157ms/step - loss: 1.2144 - accuracy: 0.5417 - val_loss: 1.2263 - val_accuracy: 0.5393\n",
      "Epoch 12/25\n",
      "12495/12495 [==============================] - 1977s 158ms/step - loss: 1.2134 - accuracy: 0.5419 - val_loss: 1.2161 - val_accuracy: 0.5440\n",
      "Epoch 13/25\n",
      "12495/12495 [==============================] - 1963s 157ms/step - loss: 1.2119 - accuracy: 0.5425 - val_loss: 1.2231 - val_accuracy: 0.5405\n",
      "Epoch 14/25\n",
      "12495/12495 [==============================] - 1978s 158ms/step - loss: 1.2113 - accuracy: 0.5437 - val_loss: 1.2285 - val_accuracy: 0.5351\n",
      "Epoch 15/25\n",
      "12495/12495 [==============================] - 1967s 157ms/step - loss: 1.2106 - accuracy: 0.5435 - val_loss: 1.2268 - val_accuracy: 0.5348\n",
      "Epoch 16/25\n",
      "12495/12495 [==============================] - 1976s 158ms/step - loss: 1.2096 - accuracy: 0.5438 - val_loss: 1.2258 - val_accuracy: 0.5366\n",
      "Epoch 17/25\n",
      "12495/12495 [==============================] - 1968s 158ms/step - loss: 1.2090 - accuracy: 0.5443 - val_loss: 1.2289 - val_accuracy: 0.5354\n",
      "Epoch 18/25\n",
      "12495/12495 [==============================] - 1975s 158ms/step - loss: 1.2094 - accuracy: 0.5437 - val_loss: 1.2143 - val_accuracy: 0.5426\n",
      "Epoch 19/25\n",
      "12495/12495 [==============================] - 1971s 158ms/step - loss: 1.2086 - accuracy: 0.5437 - val_loss: 1.2228 - val_accuracy: 0.5375\n",
      "Epoch 20/25\n",
      "12495/12495 [==============================] - 1964s 157ms/step - loss: 1.2081 - accuracy: 0.5447 - val_loss: 1.2334 - val_accuracy: 0.5351\n",
      "Epoch 21/25\n",
      "12495/12495 [==============================] - 1965s 157ms/step - loss: 1.2080 - accuracy: 0.5449 - val_loss: 1.2251 - val_accuracy: 0.5363\n",
      "Epoch 22/25\n",
      "12495/12495 [==============================] - 1943s 155ms/step - loss: 1.2068 - accuracy: 0.5446 - val_loss: 1.2298 - val_accuracy: 0.5390\n",
      "Epoch 23/25\n",
      "12495/12495 [==============================] - 1960s 157ms/step - loss: 1.2071 - accuracy: 0.5450 - val_loss: 1.2437 - val_accuracy: 0.5284\n",
      "Epoch 24/25\n",
      "12495/12495 [==============================] - 1974s 158ms/step - loss: 1.2069 - accuracy: 0.5451 - val_loss: 1.2166 - val_accuracy: 0.5417\n",
      "Epoch 25/25\n",
      "12495/12495 [==============================] - 1988s 159ms/step - loss: 1.2068 - accuracy: 0.5451 - val_loss: 1.2243 - val_accuracy: 0.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce0c7bd520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_s, validation_data=validation_s, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5473926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('1005_frozen_effiB4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1607ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "for layer in model.layers[1].layers:\n",
    "    if isinstance(layer, keras.layers.BatchNormalization):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a191e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "095d2ecf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13fef656",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12495/12495 [==============================] - 9638s 770ms/step - loss: 0.7277 - accuracy: 0.7301 - val_loss: 0.5995 - val_accuracy: 0.7836\n",
      "Epoch 2/10\n",
      "12495/12495 [==============================] - 9582s 767ms/step - loss: 0.4706 - accuracy: 0.8285 - val_loss: 0.5687 - val_accuracy: 0.8079\n",
      "Epoch 3/10\n",
      "12495/12495 [==============================] - 9544s 764ms/step - loss: 0.3146 - accuracy: 0.8850 - val_loss: 0.6388 - val_accuracy: 0.8098\n",
      "Epoch 4/10\n",
      "12495/12495 [==============================] - 9535s 763ms/step - loss: 0.2217 - accuracy: 0.9183 - val_loss: 0.6840 - val_accuracy: 0.8137\n",
      "Epoch 5/10\n",
      "12495/12495 [==============================] - 9533s 763ms/step - loss: 0.1707 - accuracy: 0.9375 - val_loss: 0.8069 - val_accuracy: 0.8086\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(training_s, validation_data=validation_s, epochs=10, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a99d8b14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495/12495 [==============================] - 1741s 139ms/step - loss: 0.3697 - accuracy: 0.8656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36973732709884644, 0.865623414516449]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab616d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593/1593 [==============================] - 224s 141ms/step - loss: 0.5687 - accuracy: 0.8079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5687124133110046, 0.8078787922859192]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bc52154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"1005_B4_eval.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
