{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd15f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS']='0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bddad8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/media/windows/'\n",
    "training = ALL_DATA_DIR + 'AffectNet_train_set/seven/'\n",
    "validation = ALL_DATA_DIR + 'AffectNet_val_set/seven/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c83fcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "img_height = 224\n",
    "img_width = 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a89e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 283901 files belonging to 7 classes.\n",
      "Found 3500 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "training_s = tf.keras.utils.image_dataset_from_directory(training, labels = 'inferred',\n",
    "            image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)\n",
    "validation_s = tf.keras.utils.image_dataset_from_directory(validation, labels = 'inferred', \n",
    "            image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1bd9cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.EfficientNetB4(input_shape=(224,224,3), include_top = False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12aec1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(7, activation='softmax')(avg)\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cde5774",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b90e5b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55fb4ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8872/8872 [==============================] - 1311s 146ms/step - loss: 1.0247 - accuracy: 0.6322 - val_loss: 2.0572 - val_accuracy: 0.3254\n",
      "Epoch 2/5\n",
      "8872/8872 [==============================] - 1320s 149ms/step - loss: 0.9781 - accuracy: 0.6481 - val_loss: 1.9505 - val_accuracy: 0.3449\n",
      "Epoch 3/5\n",
      "8872/8872 [==============================] - 1321s 149ms/step - loss: 0.9670 - accuracy: 0.6517 - val_loss: 2.0263 - val_accuracy: 0.3351\n",
      "Epoch 4/5\n",
      "8872/8872 [==============================] - 1309s 148ms/step - loss: 0.9620 - accuracy: 0.6543 - val_loss: 1.9880 - val_accuracy: 0.3557\n",
      "Epoch 5/5\n",
      "8872/8872 [==============================] - 1310s 148ms/step - loss: 0.9583 - accuracy: 0.6544 - val_loss: 2.0232 - val_accuracy: 0.3400\n"
     ]
    }
   ],
   "source": [
    "model.fit(training_s, validation_data=validation_s, epochs=5)\n",
    "model.save('0919_Affect_EfB4_frozen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b257c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a191e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095d2ecf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fef656",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8872/8872 [==============================] - 6506s 731ms/step - loss: 0.6909 - accuracy: 0.7495 - val_loss: 1.3321 - val_accuracy: 0.5380\n",
      "Epoch 2/20\n",
      "8872/8872 [==============================] - 6486s 731ms/step - loss: 0.5647 - accuracy: 0.7922 - val_loss: 1.2522 - val_accuracy: 0.5740\n",
      "Epoch 3/20\n",
      "8872/8872 [==============================] - 6476s 730ms/step - loss: 0.4738 - accuracy: 0.8236 - val_loss: 1.4375 - val_accuracy: 0.5609\n",
      "Epoch 4/20\n",
      "8872/8872 [==============================] - 6470s 729ms/step - loss: 0.3708 - accuracy: 0.8600 - val_loss: 1.5825 - val_accuracy: 0.5751\n",
      "Epoch 5/20\n",
      "8872/8872 [==============================] - 6477s 730ms/step - loss: 0.2842 - accuracy: 0.8919 - val_loss: 1.8728 - val_accuracy: 0.5669\n",
      "Epoch 6/20\n",
      "8872/8872 [==============================] - 6479s 730ms/step - loss: 0.2285 - accuracy: 0.9143 - val_loss: 2.0817 - val_accuracy: 0.5617\n",
      "Epoch 7/20\n",
      "8872/8872 [==============================] - 6478s 730ms/step - loss: 0.1897 - accuracy: 0.9289 - val_loss: 2.4019 - val_accuracy: 0.5697\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(training_s, validation_data=validation_s, epochs=20, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc52154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"0919_Affect_B4_eval.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f30e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
