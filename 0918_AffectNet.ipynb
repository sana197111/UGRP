{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd15f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS']='0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bddad8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/media/windows/'\n",
    "training = ALL_DATA_DIR + 'AffectNet_train_set/seven/'\n",
    "validation = ALL_DATA_DIR + 'AffectNet_val_set/seven/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c83fcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "img_height = 224\n",
    "img_width = 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a89e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 283901 files belonging to 7 classes.\n",
      "Found 3500 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "training_s = tf.keras.utils.image_dataset_from_directory(training, labels = 'inferred',\n",
    "            image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)\n",
    "validation_s = tf.keras.utils.image_dataset_from_directory(validation, labels = 'inferred', \n",
    "            image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1bd9cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.MobileNetV3Small(input_shape=(224,224,3), include_top = False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12aec1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(7, activation='softmax')(avg)\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cde5774",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b90e5b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55fb4ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8872/8872 [==============================] - 245s 27ms/step - loss: 1.1353 - accuracy: 0.5847 - val_loss: 2.2067 - val_accuracy: 0.2591\n",
      "Epoch 2/5\n",
      "8872/8872 [==============================] - 224s 25ms/step - loss: 1.0769 - accuracy: 0.6074 - val_loss: 2.1123 - val_accuracy: 0.2803\n",
      "Epoch 3/5\n",
      "8872/8872 [==============================] - 226s 25ms/step - loss: 1.0706 - accuracy: 0.6092 - val_loss: 2.1458 - val_accuracy: 0.2769\n",
      "Epoch 4/5\n",
      "8872/8872 [==============================] - 225s 25ms/step - loss: 1.0678 - accuracy: 0.6106 - val_loss: 2.1829 - val_accuracy: 0.2826\n",
      "Epoch 5/5\n",
      "8872/8872 [==============================] - 225s 25ms/step - loss: 1.0670 - accuracy: 0.6109 - val_loss: 2.1787 - val_accuracy: 0.2811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5cde50160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_s, validation_data=validation_s, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b257c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a191e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095d2ecf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fef656",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8872/8872 [==============================] - 549s 61ms/step - loss: 0.7657 - accuracy: 0.7251 - val_loss: 1.5353 - val_accuracy: 0.4740\n",
      "Epoch 2/30\n",
      "8872/8872 [==============================] - 545s 61ms/step - loss: 0.6402 - accuracy: 0.7667 - val_loss: 1.3796 - val_accuracy: 0.5283\n",
      "Epoch 3/30\n",
      "8872/8872 [==============================] - 545s 61ms/step - loss: 0.5975 - accuracy: 0.7811 - val_loss: 1.4105 - val_accuracy: 0.5257\n",
      "Epoch 4/30\n",
      "8872/8872 [==============================] - 544s 61ms/step - loss: 0.5642 - accuracy: 0.7925 - val_loss: 1.3496 - val_accuracy: 0.5497\n",
      "Epoch 5/30\n",
      "8872/8872 [==============================] - 538s 61ms/step - loss: 0.5333 - accuracy: 0.8034 - val_loss: 1.4060 - val_accuracy: 0.5457\n",
      "Epoch 6/30\n",
      "8872/8872 [==============================] - 545s 61ms/step - loss: 0.5022 - accuracy: 0.8143 - val_loss: 1.4863 - val_accuracy: 0.5446\n",
      "Epoch 7/30\n",
      "8872/8872 [==============================] - 543s 61ms/step - loss: 0.4727 - accuracy: 0.8248 - val_loss: 1.5875 - val_accuracy: 0.5411\n",
      "Epoch 8/30\n",
      "8872/8872 [==============================] - 539s 61ms/step - loss: 0.4419 - accuracy: 0.8372 - val_loss: 1.5255 - val_accuracy: 0.5466\n",
      "Epoch 9/30\n",
      "8872/8872 [==============================] - 539s 61ms/step - loss: 0.4134 - accuracy: 0.8466 - val_loss: 1.5817 - val_accuracy: 0.5489\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(training_s, validation_data=validation_s, epochs=30, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c223c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8872/8872 [==============================] - 224s 25ms/step - loss: 0.5413 - accuracy: 0.8009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5413046479225159, 0.8008989095687866]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d209d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 3s 23ms/step - loss: 1.3496 - accuracy: 0.5497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3496047258377075, 0.5497142672538757]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc52154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"0926_mobile_affect_eval.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
