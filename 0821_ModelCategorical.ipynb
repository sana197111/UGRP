{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd15f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS']='0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91bddad8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/media/windows/'\n",
    "training = ALL_DATA_DIR + 'training/'\n",
    "validation = ALL_DATA_DIR + 'validation/'\n",
    "scaled = ALL_DATA_DIR + 'scaled/'\n",
    "scaled_wo_rotate = ALL_DATA_DIR + \"scaled_wo_rotate/\"\n",
    "\n",
    "scaled_wo_rotate_training = scaled_wo_rotate + \"training/\"\n",
    "scaled_wo_rotate_validation = scaled_wo_rotate + \"validation/\"\n",
    "\n",
    "datFile = training + \"shape_predictor_68_face_landmarks.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c83fcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "img_height = 224\n",
    "img_width = 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74be57c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50947 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_ds = tf.keras.utils.image_dataset_from_directory(scaled_wo_rotate_validation, labels = 'inferred', \n",
    "            label_mode = 'int', image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd9f883",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399839 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "training_ds = tf.keras.utils.image_dataset_from_directory(scaled_wo_rotate_training, labels = 'inferred',\n",
    "            label_mode = 'int', image_size=(img_height,img_width), batch_size=batch_size, seed=42).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1bd9cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.MobileNetV3Small(input_shape=(224,224,3), include_top = False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12aec1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(7, activation='softmax')(avg)\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cde5774",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b90e5b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b55fb4ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "12495/12495 [==============================] - 479s 38ms/step - loss: 1.4990 - accuracy: 0.4277 - val_loss: 1.4195 - val_accuracy: 0.4642\n",
      "Epoch 2/3\n",
      "12495/12495 [==============================] - 537s 43ms/step - loss: 1.4167 - accuracy: 0.4607 - val_loss: 1.4086 - val_accuracy: 0.4632\n",
      "Epoch 3/3\n",
      "12495/12495 [==============================] - 407s 33ms/step - loss: 1.4066 - accuracy: 0.4652 - val_loss: 1.3993 - val_accuracy: 0.4697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc59b4ee80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_ds, validation_data=validation_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64b257c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9a191e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "095d2ecf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b7e453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = keras.callbacks.ModelCheckpoint('0821_model', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04b71c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50947 files belonging to 7 classes.\n",
      "Found 399839 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_s = tf.keras.utils.image_dataset_from_directory(scaled_wo_rotate_validation, labels = 'inferred', \n",
    "            label_mode = 'int', image_size=(img_height,img_width), batch_size=1, shuffle=False)\n",
    "training_s = tf.keras.utils.image_dataset_from_directory(scaled_wo_rotate_training, labels = 'inferred',\n",
    "            label_mode = 'int', image_size=(img_height,img_width), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13fef656",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12495/12495 [==============================] - ETA: 0s - loss: 0.9340 - accuracy: 0.6515"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495/12495 [==============================] - 850s 68ms/step - loss: 0.9340 - accuracy: 0.6515 - val_loss: 0.7836 - val_accuracy: 0.7088\n",
      "Epoch 2/10\n",
      "12495/12495 [==============================] - ETA: 0s - loss: 0.7275 - accuracy: 0.7284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495/12495 [==============================] - 844s 68ms/step - loss: 0.7275 - accuracy: 0.7284 - val_loss: 0.7067 - val_accuracy: 0.7420\n",
      "Epoch 3/10\n",
      "12495/12495 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.7628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495/12495 [==============================] - 844s 68ms/step - loss: 0.6406 - accuracy: 0.7628 - val_loss: 0.6699 - val_accuracy: 0.7566\n",
      "Epoch 4/10\n",
      "12495/12495 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.7870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495/12495 [==============================] - 845s 68ms/step - loss: 0.5756 - accuracy: 0.7870 - val_loss: 0.6577 - val_accuracy: 0.7634\n",
      "Epoch 5/10\n",
      "12495/12495 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.8073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495/12495 [==============================] - 841s 67ms/step - loss: 0.5251 - accuracy: 0.8073 - val_loss: 0.6445 - val_accuracy: 0.7723\n",
      "Epoch 6/10\n",
      "12495/12495 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.8226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0821_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12495/12495 [==============================] - 842s 67ms/step - loss: 0.4831 - accuracy: 0.8226 - val_loss: 0.6378 - val_accuracy: 0.7751\n",
      "Epoch 7/10\n",
      "12495/12495 [==============================] - 829s 66ms/step - loss: 0.4460 - accuracy: 0.8363 - val_loss: 0.6816 - val_accuracy: 0.7653\n",
      "Epoch 8/10\n",
      "12495/12495 [==============================] - 829s 66ms/step - loss: 0.4136 - accuracy: 0.8486 - val_loss: 0.6565 - val_accuracy: 0.7775\n",
      "Epoch 9/10\n",
      "12495/12495 [==============================] - 833s 67ms/step - loss: 0.3859 - accuracy: 0.8585 - val_loss: 0.6694 - val_accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(training_ds, validation_data=validation_ds, epochs=10, callbacks=[cp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a99d8b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['validation_anger',\n",
       " 'validation_disgust',\n",
       " 'validation_fear',\n",
       " 'validation_happiness',\n",
       " 'validation_neutral',\n",
       " 'validation_sadness',\n",
       " 'validation_surprise']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_s.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e161f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 809ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "B = []\n",
    "C = []\n",
    "D = []\n",
    "for image, label in validation_s.take(5):\n",
    "    A = model.predict(image, label)\n",
    "    B.append(A.round(2))\n",
    "    C.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6a6629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.7274448e-01, 3.7470538e-02, 1.8059179e-01, 4.3732810e-04,\n",
       "         1.1666359e-02, 5.1117642e-03, 4.9197772e-01]], dtype=float32),\n",
       " array([[9.9924278e-01, 7.5254567e-05, 1.5620465e-04, 1.7920227e-06,\n",
       "         1.1429091e-04, 3.8608481e-04, 2.3581419e-05]], dtype=float32),\n",
       " array([[9.3479854e-01, 1.6944256e-02, 3.6108498e-02, 5.0345826e-04,\n",
       "         2.2689122e-05, 1.8735834e-03, 9.7489916e-03]], dtype=float32),\n",
       " array([[8.2547951e-01, 1.6870426e-02, 1.4382675e-01, 2.5117747e-06,\n",
       "         5.4438069e-04, 5.7362777e-04, 1.2702723e-02]], dtype=float32),\n",
       " array([[9.7870752e-02, 1.0748791e-01, 9.7099744e-02, 1.1581975e-04,\n",
       "         4.3229669e-05, 6.9410884e-01, 3.2737511e-03]], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1bc52154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"0821_Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
