{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a57abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0173a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_tb_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecf6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)\n",
    "dataset_size = info.splits[\"train\"].num_examples\n",
    "class_names = info.features[\"label\"].names\n",
    "n_classes = info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb504d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_raw, valid_set_raw, train_set_raw = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f56c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4369d17a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_set = train_set_raw.shuffle(1000)\n",
    "train_set = train_set.map(preprocess).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "518ddf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842002bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "906324bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93973dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "344/344 [==============================] - 31s 77ms/step - loss: 3.0860 - accuracy: 0.8089 - val_loss: 1.9439 - val_accuracy: 0.8657\n",
      "Epoch 2/5\n",
      "344/344 [==============================] - 26s 75ms/step - loss: 0.7133 - accuracy: 0.9248 - val_loss: 1.8550 - val_accuracy: 0.8566\n",
      "Epoch 3/5\n",
      "344/344 [==============================] - 26s 75ms/step - loss: 0.3337 - accuracy: 0.9488 - val_loss: 1.8578 - val_accuracy: 0.8457\n",
      "Epoch 4/5\n",
      "344/344 [==============================] - 26s 76ms/step - loss: 0.2154 - accuracy: 0.9611 - val_loss: 1.8066 - val_accuracy: 0.8439\n",
      "Epoch 5/5\n",
      "344/344 [==============================] - 26s 76ms/step - loss: 0.1342 - accuracy: 0.9691 - val_loss: 1.6338 - val_accuracy: 0.8494\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, validation_data=valid_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e2b331b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current': 94383616, 'peak': 1883904768}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba6133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "344/344 [==============================] - 108s 299ms/step - loss: 1.0578 - accuracy: 0.6134 - val_loss: 8.2194 - val_accuracy: 0.4374\n",
      "Epoch 2/40\n",
      "344/344 [==============================] - 103s 299ms/step - loss: 0.5697 - accuracy: 0.7983 - val_loss: 0.5508 - val_accuracy: 0.7967\n",
      "Epoch 3/40\n",
      "344/344 [==============================] - 103s 300ms/step - loss: 0.3841 - accuracy: 0.8583 - val_loss: 0.3222 - val_accuracy: 0.8784\n",
      "Epoch 4/40\n",
      "344/344 [==============================] - 103s 300ms/step - loss: 0.2344 - accuracy: 0.9168 - val_loss: 0.3508 - val_accuracy: 0.9093\n",
      "Epoch 5/40\n",
      "344/344 [==============================] - 103s 301ms/step - loss: 0.1389 - accuracy: 0.9528 - val_loss: 0.5531 - val_accuracy: 0.8802\n",
      "Epoch 6/40\n",
      "344/344 [==============================] - 104s 302ms/step - loss: 0.1151 - accuracy: 0.9644 - val_loss: 0.3086 - val_accuracy: 0.9056\n",
      "Epoch 7/40\n",
      "344/344 [==============================] - 104s 302ms/step - loss: 0.0818 - accuracy: 0.9717 - val_loss: 0.8749 - val_accuracy: 0.8857\n",
      "Epoch 8/40\n",
      "344/344 [==============================] - 104s 302ms/step - loss: 0.0700 - accuracy: 0.9775 - val_loss: 0.6363 - val_accuracy: 0.8947\n",
      "Epoch 9/40\n",
      "344/344 [==============================] - 104s 303ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 0.4527 - val_accuracy: 0.8820\n",
      "Epoch 10/40\n",
      "344/344 [==============================] - 104s 303ms/step - loss: 0.0434 - accuracy: 0.9858 - val_loss: 0.3282 - val_accuracy: 0.9020\n",
      "Epoch 11/40\n",
      "344/344 [==============================] - 105s 304ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.4168 - val_accuracy: 0.9074\n",
      "Epoch 12/40\n",
      "344/344 [==============================] - 104s 304ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.2860 - val_accuracy: 0.9183\n",
      "Epoch 13/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.2667 - val_accuracy: 0.9274\n",
      "Epoch 14/40\n",
      "344/344 [==============================] - 105s 304ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.2685 - val_accuracy: 0.9292\n",
      "Epoch 15/40\n",
      "344/344 [==============================] - 105s 304ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.3603 - val_accuracy: 0.9220\n",
      "Epoch 16/40\n",
      "344/344 [==============================] - 105s 304ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.2958 - val_accuracy: 0.9310\n",
      "Epoch 17/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.4084 - val_accuracy: 0.9165\n",
      "Epoch 18/40\n",
      "344/344 [==============================] - 105s 306ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.3630 - val_accuracy: 0.9256\n",
      "Epoch 19/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.3060 - val_accuracy: 0.9238\n",
      "Epoch 20/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.3164 - val_accuracy: 0.9256\n",
      "Epoch 21/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.3210 - val_accuracy: 0.9183\n",
      "Epoch 22/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.3390 - val_accuracy: 0.9183\n",
      "Epoch 23/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4045 - val_accuracy: 0.9111\n",
      "Epoch 24/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 0.7693 - val_accuracy: 0.9093\n",
      "Epoch 25/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.4771 - val_accuracy: 0.9238\n",
      "Epoch 26/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.4864 - val_accuracy: 0.9147\n",
      "Epoch 27/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0066 - accuracy: 0.9971 - val_loss: 0.5944 - val_accuracy: 0.9111\n",
      "Epoch 28/40\n",
      "344/344 [==============================] - 105s 304ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.7306 - val_accuracy: 0.9093\n",
      "Epoch 29/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.5124 - val_accuracy: 0.9165\n",
      "Epoch 30/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5794 - val_accuracy: 0.9147\n",
      "Epoch 31/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.5915 - val_accuracy: 0.9183\n",
      "Epoch 32/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.5733 - val_accuracy: 0.9165\n",
      "Epoch 33/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.6994 - val_accuracy: 0.9093\n",
      "Epoch 34/40\n",
      "344/344 [==============================] - 105s 306ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.5858 - val_accuracy: 0.9183\n",
      "Epoch 35/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.5828 - val_accuracy: 0.9201\n",
      "Epoch 36/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.5411 - val_accuracy: 0.9238\n",
      "Epoch 37/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.4904 - val_accuracy: 0.9220\n",
      "Epoch 38/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.5087 - val_accuracy: 0.9183\n",
      "Epoch 39/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5242 - val_accuracy: 0.9165\n",
      "Epoch 40/40\n",
      "344/344 [==============================] - 105s 305ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.4572 - val_accuracy: 0.9201\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=True\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9,\n",
    "                                 nesterov=True, decay=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=40, validation_data=valid_set, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8d455ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 3s 62ms/step - loss: 0.6338 - accuracy: 0.9155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6337935924530029, 0.9155313372612]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f27f66a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current': 177932544, 'peak': 1883904768}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
